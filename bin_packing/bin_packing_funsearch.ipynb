{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Run FunSearch on Bin Packing\n",
    "Five steps:\n",
    "1. Implement 'LLM' interface.\n",
    "2. Implement a 'SandBox' interface.\n",
    "3. Prepare a 'specification'.\n",
    "4. Prepare a dataset.\n",
    "5. Start FunSearch."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58ba1915fced4e72"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Implement LLM interface\n",
    "You should prepare a 'key' for the LLM API. And fill them in the header.\n",
    "```python\n",
    "headers = {\n",
    "    'Authorization': 'Bearer [put your key here, may start with \"sk-...\"]',\n",
    "    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe47175708cc0a93"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "from typing import Collection, Any\n",
    "import http.client\n",
    "from implementation import sampler\n",
    "\n",
    "\n",
    "class LLMAPI(sampler.LLM):\n",
    "    \"\"\"Language model that predicts continuation of provided source code.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, samples_per_prompt: int):\n",
    "        super().__init__(samples_per_prompt)\n",
    "        additional_prompt = ('Complete a different and more complex Python function. '\n",
    "                             'Be creative and you can insert multiple if-else and for-loop in the code logic.'\n",
    "                             'Only output the Python code, no descriptions.')\n",
    "        self._additional_prompt = additional_prompt\n",
    "\n",
    "    def draw_samples(self, prompt: str) -> Collection[str]:\n",
    "        \"\"\"Returns multiple predicted continuations of `prompt`.\"\"\"\n",
    "        return [self._draw_sample(prompt) for _ in range(self._samples_per_prompt)]\n",
    "\n",
    "    def _draw_sample(self, content: str) -> str:\n",
    "        prompt = '\\n'.join([content, self._additional_prompt])\n",
    "        while True:\n",
    "            try:\n",
    "                conn = http.client.HTTPSConnection(\"api.chatanywhere.com.cn\")\n",
    "                payload = json.dumps({\n",
    "                    \"max_tokens\": 512,\n",
    "                    \"model\": \"gpt-3.5-turbo\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "                headers = {\n",
    "                    'Authorization': 'Bearer sk-ys02zxw9Lf3cjL7IfCufrfXE0ZPhAmUyzR8pCyPVsIeIrklJ',\n",
    "                    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
    "                    'Content-Type': 'application/json'\n",
    "                }\n",
    "                conn.request(\"POST\", \"/v1/chat/completions\", payload, headers)\n",
    "                res = conn.getresponse()\n",
    "                data = res.read().decode(\"utf-8\")\n",
    "                data = json.loads(data)\n",
    "                response = data['choices'][0]['message']['content']\n",
    "                return response\n",
    "            except Exception:\n",
    "                continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T16:32:26.696326Z",
     "start_time": "2024-02-06T16:32:26.676072Z"
    }
   },
   "id": "1999e45c9a568b08"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Implement a 'SandBox' interface"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d27817cdec2cedfc"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from implementation import evaluator\n",
    "from implementation import evaluator_accelerate\n",
    "from implementation import code_manipulation\n",
    "\n",
    "\n",
    "class Sandbox(evaluator.Sandbox):\n",
    "    \"\"\"Sandbox for executing generated code. Implemented by RZ.\n",
    "\n",
    "    RZ: Sandbox returns the 'score' of the program and:\n",
    "    1) avoids the generated code to be harmful (accessing the internet, take up too much RAM).\n",
    "    2) stops the execution of the code in time (avoid endless loop).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=False, numba_accelerate=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            verbose         : Print evaluate information.\n",
    "            numba_accelerate: Use numba to accelerate the evaluation. It should be noted that not all numpy functions\n",
    "                              support numba acceleration, such as np.piecewise().\n",
    "        \"\"\"\n",
    "        self._verbose = verbose\n",
    "        self._numba_accelerate = numba_accelerate\n",
    "\n",
    "    def run(\n",
    "            self,\n",
    "            program: str,\n",
    "            function_to_run: str,  # RZ: refers to the name of the function to run (e.g., 'evaluate')\n",
    "            function_to_evolve: str,  # RZ: accelerate the code by decorating @numba.jit() on function_to_evolve.\n",
    "            inputs: Any,  # refers to the dataset\n",
    "            test_input: str,  # refers to the current instance\n",
    "            timeout_seconds: int,\n",
    "            **kwargs  # RZ: add this\n",
    "    ) -> tuple[Any, bool]:\n",
    "        \"\"\"Returns `function_to_run(test_input)` and whether execution succeeded.\n",
    "\n",
    "        RZ: If the generated code (generated by LLM) is executed successfully,\n",
    "        the output of this function is the score of a given program.\n",
    "        RZ: PLEASE NOTE THAT this SandBox is only designed for bin-packing problem.\n",
    "        \"\"\"\n",
    "        dataset = inputs[test_input]\n",
    "        result_queue = multiprocessing.Queue()\n",
    "        process = multiprocessing.Process(\n",
    "            target=self._compile_and_run_function,\n",
    "            args=(program, function_to_run, function_to_evolve, dataset, self._numba_accelerate, result_queue)\n",
    "        )\n",
    "        process.start()\n",
    "        process.join(timeout=timeout_seconds)\n",
    "        if process.is_alive():\n",
    "            # if the process is not finished in time, we consider the program illegal\n",
    "            process.terminate()\n",
    "            process.join()\n",
    "            results = None, False\n",
    "        else:\n",
    "            if result_queue.qsize() != 0:\n",
    "                results = result_queue.get_nowait()\n",
    "            else:\n",
    "                results = None, False\n",
    "\n",
    "        if self._verbose:\n",
    "            print(f'================= Evaluated Program =================')\n",
    "            program_: code_manipulation.Program = code_manipulation.text_to_program(text=program)\n",
    "            func_to_evolve_: str = kwargs.get('func_to_evolve', 'priority')\n",
    "            function_: code_manipulation.Function = program_.get_function(func_to_evolve_)\n",
    "            function_: str = str(function_).strip('\\n')\n",
    "            print(f'{function_}')\n",
    "            print(f'-----------------------------------------------------')\n",
    "            print(f'Score: {str(results)}')\n",
    "            print(f'=====================================================')\n",
    "            print(f'\\n\\n')\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _compile_and_run_function(self, program, function_to_run, function_to_evolve, dataset, numba_accelerate,\n",
    "                                  result_queue):\n",
    "        try:\n",
    "            # optimize the code (decorate function_to_run with @numba.jit())\n",
    "            if numba_accelerate:\n",
    "                program = evaluator_accelerate.add_numba_decorator(\n",
    "                    program=program,\n",
    "                    function_to_evolve=function_to_evolve\n",
    "                )\n",
    "            # compile the program, and maps the global func/var/class name to its address\n",
    "            all_globals_namespace = {}\n",
    "            # execute the program, map func/var/class to global namespace\n",
    "            exec(program, all_globals_namespace)\n",
    "            # get the pointer of 'function_to_run'\n",
    "            function_to_run = all_globals_namespace[function_to_run]\n",
    "            # return the execution results\n",
    "            results = function_to_run(dataset)\n",
    "            # the results must be int or float\n",
    "            if not isinstance(results, (int, float)):\n",
    "                result_queue.put((None, False))\n",
    "                return\n",
    "            result_queue.put((results, True))\n",
    "        except Exception:\n",
    "            # if raise any exception, we assume the execution failed\n",
    "            result_queue.put((None, False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T16:32:26.715013Z",
     "start_time": "2024-02-06T16:32:26.687256Z"
    }
   },
   "id": "3e3d88a87535b6b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Prepare a 'specification'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec3a05827354f9ae"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "specification = r'''\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_valid_bin_indices(item: float, bins: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Returns indices of bins in which item can fit.\"\"\"\n",
    "    return np.nonzero((bins - item) >= 0)[0]\n",
    "\n",
    "\n",
    "def online_binpack(\n",
    "        items: tuple[float, ...], bins: np.ndarray\n",
    ") -> tuple[list[list[float, ...], ...], np.ndarray]:\n",
    "    \"\"\"Performs online binpacking of `items` into `bins`.\"\"\"\n",
    "    # Track which items are added to each bin.\n",
    "    packing = [[] for _ in bins]\n",
    "    # Add items to bins.\n",
    "    for item in items:\n",
    "        # Extract bins that have sufficient space to fit item.\n",
    "        valid_bin_indices = get_valid_bin_indices(item, bins)\n",
    "        # Score each bin based on heuristic.\n",
    "        priorities = priority(item, bins[valid_bin_indices])\n",
    "        # Add item to bin with highest priority.\n",
    "        best_bin = valid_bin_indices[np.argmax(priorities)]\n",
    "        bins[best_bin] -= item\n",
    "        packing[best_bin].append(item)\n",
    "    # Remove unused bins from packing.\n",
    "    packing = [bin_items for bin_items in packing if bin_items]\n",
    "    return packing, bins\n",
    "\n",
    "\n",
    "@funsearch.run\n",
    "def evaluate(instances: dict) -> float:\n",
    "    \"\"\"Evaluate heuristic function on a set of online binpacking instances.\"\"\"\n",
    "    # List storing number of bins used for each instance.\n",
    "    num_bins = []\n",
    "    # Perform online binpacking for each instance.\n",
    "    for name in instances:\n",
    "        instance = instances[name]\n",
    "        capacity = instance['capacity']\n",
    "        items = instance['items']\n",
    "        # Create num_items bins so there will always be space for all items,\n",
    "        # regardless of packing order. Array has shape (num_items,).\n",
    "        bins = np.array([capacity for _ in range(instance['num_items'])])\n",
    "        # Pack items into bins and return remaining capacity in bins_packed, which\n",
    "        # has shape (num_items,).\n",
    "        _, bins_packed = online_binpack(items, bins)\n",
    "        # If remaining capacity in a bin is equal to initial capacity, then it is\n",
    "        # unused. Count number of used bins.\n",
    "        num_bins.append((bins_packed != capacity).sum())\n",
    "    # Score of heuristic function is negative of average number of bins used\n",
    "    # across instances (as we want to minimize number of bins).\n",
    "    return -np.mean(num_bins)\n",
    "\n",
    "\n",
    "@funsearch.evolve\n",
    "def priority(item: float, bins: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Returns priority with which we want to add item to each bin.\n",
    "\n",
    "    Args:\n",
    "        item: Size of item to be added to the bin.\n",
    "        bins: Array of capacities for each bin.\n",
    "\n",
    "    Return:\n",
    "        Array of same size as bins with priority score of each bin.\n",
    "    \"\"\"\n",
    "    ratios = item / bins\n",
    "    log_ratios = np.log(ratios)\n",
    "    priorities = -log_ratios\n",
    "    return priorities\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T16:32:26.715549Z",
     "start_time": "2024-02-06T16:32:26.702390Z"
    }
   },
   "id": "2e2f875d128a693a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Prepare a dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "391bfe61e1661e18"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import bin_packing_utils\n",
    "\n",
    "bin_packing_or3 = {'OR3': bin_packing_utils.datasets['OR3']}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T16:32:26.715788Z",
     "start_time": "2024-02-06T16:32:26.710226Z"
    }
   },
   "id": "fea85ccfc8c0ca6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Start FunSearch\n",
    "Please note that in jupyter notebook the following code will fail. This is because juypter does not support multiprocessing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb66651fb2764ce9"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/llm39/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/llm39/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'Sandbox' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m config \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mConfig(samples_per_prompt\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m      9\u001B[0m global_max_sample_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m  \u001B[38;5;66;03m# if it is set to None, funsearch will execute an endless loop\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[43mfunsearch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mspecification\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspecification\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbin_packing_or3\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_sample_nums\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mglobal_max_sample_num\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../logs/funsearch_llm_api\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m     17\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/funsearch-rz/implementation/funsearch.py:91\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(specification, inputs, config, max_sample_nums, class_config, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;66;03m# We send the initial implementation to be analysed by one of the evaluators.\u001B[39;00m\n\u001B[1;32m     90\u001B[0m initial \u001B[38;5;241m=\u001B[39m template\u001B[38;5;241m.\u001B[39mget_function(function_to_evolve)\u001B[38;5;241m.\u001B[39mbody\n\u001B[0;32m---> 91\u001B[0m \u001B[43mevaluators\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manalyse\u001B[49m\u001B[43m(\u001B[49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43misland_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mversion_generated\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprofiler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprofiler\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;66;03m# Set global max sample nums.\u001B[39;00m\n\u001B[1;32m     94\u001B[0m samplers \u001B[38;5;241m=\u001B[39m [sampler\u001B[38;5;241m.\u001B[39mSampler(database, evaluators, config\u001B[38;5;241m.\u001B[39msamples_per_prompt, max_sample_nums\u001B[38;5;241m=\u001B[39mmax_sample_nums, llm_class\u001B[38;5;241m=\u001B[39mclass_config\u001B[38;5;241m.\u001B[39mllm_class)\n\u001B[1;32m     95\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(config\u001B[38;5;241m.\u001B[39mnum_samplers)]\n",
      "File \u001B[0;32m~/Desktop/funsearch-rz/implementation/evaluator.py:222\u001B[0m, in \u001B[0;36mEvaluator.analyse\u001B[0;34m(self, sample, island_id, version_generated, **kwargs)\u001B[0m\n\u001B[1;32m    216\u001B[0m time_reset \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m current_input \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inputs:\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# RZ: IMPORTANT !!! if self._inputs is a dict,\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# current_input is a key (perhaps in string type)\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;66;03m# do not ignore this when implementing SandBox !!!\u001B[39;00m\n\u001B[0;32m--> 222\u001B[0m     test_output, runs_ok \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sandbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogram\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_function_to_run\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_function_to_evolve\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_timeout_seconds\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m runs_ok \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _calls_ancestor(program, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_to_evolve) \u001B[38;5;129;01mand\u001B[39;00m test_output \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    228\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(test_output, (\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mfloat\u001B[39m)):\n",
      "Cell \u001B[0;32mIn[15], line 54\u001B[0m, in \u001B[0;36mSandbox.run\u001B[0;34m(self, program, function_to_run, function_to_evolve, inputs, test_input, timeout_seconds, **kwargs)\u001B[0m\n\u001B[1;32m     52\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 54\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mresult_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mqsize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     55\u001B[0m         results \u001B[38;5;241m=\u001B[39m result_queue\u001B[38;5;241m.\u001B[39mget_nowait()\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/llm39/lib/python3.9/multiprocessing/queues.py:126\u001B[0m, in \u001B[0;36mQueue.qsize\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mqsize\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;66;03m# Raises NotImplementedError on Mac OSX because of broken sem_getvalue()\u001B[39;00m\n\u001B[0;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maxsize \u001B[38;5;241m-\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sem\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_semlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from implementation import funsearch\n",
    "from implementation import config\n",
    "\n",
    "# It should be noted that the if __name__ == '__main__' is required.\n",
    "# Because the inner code uses multiprocess evaluation.\n",
    "if __name__ == '__main__':\n",
    "    class_config = config.ClassConfig(llm_class=LLMAPI, sandbox_class=Sandbox)\n",
    "    config = config.Config(samples_per_prompt=4)\n",
    "    global_max_sample_num = 10  # if it is set to None, funsearch will execute an endless loop\n",
    "    funsearch.main(\n",
    "        specification=specification,\n",
    "        inputs=bin_packing_or3,\n",
    "        config=config,\n",
    "        max_sample_nums=global_max_sample_num,\n",
    "        class_config=class_config,\n",
    "        log_dir='../logs/funsearch_llm_api'\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T16:33:21.204825Z",
     "start_time": "2024-02-06T16:33:21.046035Z"
    }
   },
   "id": "1e0ec0c796d09ca1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T16:32:26.878015Z",
     "start_time": "2024-02-06T16:32:26.875557Z"
    }
   },
   "id": "c35dd9d0b18ff2db"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
